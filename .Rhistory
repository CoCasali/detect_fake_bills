## First specify the packages of interest
packages = c("knitr","readr","dplyr","kableExtra",'stringi','tidyverse','corrplot','psych','reshape2','GGally', 'performance', 'FactoMineR','factoextra', 'MASS','broom', "caret","blorr","rstudioapi","pROC","clue")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
install.packages(x, dependencies = TRUE)
# Reading Data
df_billet <- read.csv2("data/billets.csv", sep = ";", dec = ".")
# Visualization of the dataframe
str(df_billet) # info about data
summary(df_billet) # info about numeric data
# Missing data
sapply(df_billet, function(x) sum(is.na(x)))
# Factor is_genuine
df_billet$is_genuine = factor(df_billet$is_genuine, levels = c("True","False"), labels = c("vrai_billet","faux_billet"))
# Groupby | groupe
df_billet %>%
group_by(is_genuine)%>%
summarise_all("mean", na.rm=TRUE) %>% as.data.frame()
# Factor is_genuine
df_billet$is_genuine = factor(df_billet$is_genuine, levels = c("True","False"), labels = c("vrai_billet","faux_billet"))
# Groupby | groupe
df_billet %>%
group_by(is_genuine)%>%
summarise_all("mean", na.rm=TRUE) %>% as.data.frame()
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
install.packages(x, dependencies = TRUE)
install.packages("caret")
## Now load or install&load all
package.check <- lapply(
packages,
FUN = function(x) {
if (!require(x, character.only = TRUE)) {
install.packages(x, dependencies = TRUE)
library(x, character.only = TRUE)
}
}
)
setwd(dirname(getActiveDocumentContext()$path)) # set as working directory
knitr::opts_chunk$set(echo=TRUE, fig.height = 8, fig.width = 12, fig.align = "center")
# Reading Data
df_billet <- read.csv2("data/billets.csv", sep = ";", dec = ".")
# Visualization of the dataframe
str(df_billet) # info about data
summary(df_billet) # info about numeric data
# Missing data
sapply(df_billet, function(x) sum(is.na(x)))
# Factor is_genuine
df_billet$is_genuine = factor(df_billet$is_genuine, levels = c("True","False"), labels = c("vrai_billet","faux_billet"))
# Groupby | groupe
df_billet %>%
group_by(is_genuine)%>%
summarise_all("mean", na.rm=TRUE) %>% as.data.frame()
# Visualisation graphique des différentes variables [BOXPLOT]
df_boxplot <- df_billet %>% gather(-is_genuine, key ="var", value ="value")
ggplot(df_boxplot, aes (x = is_genuine, y=value, fill = is_genuine))+
scale_fill_manual(values=c("#91FFB4","#FFCAC9"))+
facet_wrap(~var, scales = "free")+
geom_boxplot()+
coord_flip()+
theme_bw()
# Visualization of the few missing data :
kable(head(df_billet[is.na(df_billet$margin_low),],6))%>%
kable_styling(latex_options = 'striped')
# Removing missing data from a dataframe
df_billet_dropna.full <- df_billet %>% drop_na
# Get the lower triangle in the correlation matrix
get_lower_tri<-function(cormat){
cormat[upper.tri(cormat)] <- NA
return(cormat)
}
# Linear correlation matrix
melted_cormat <- melt(get_lower_tri(round(cor(df_billet_dropna.full[,-1],use='complete.obs'),2)), na.rm = TRUE)
ggplot(data = melted_cormat,
aes(Var1, Var2, fill=value)) +
geom_tile(color = "white")+
scale_fill_gradient2(low = "red", high = "blue", mid = "white",
midpoint = 0, limit = c(-1,1),
name="Pearson\nCorrelation") +
theme_classic()+
theme(axis.text.x =
element_text(angle = 45, vjust = 1, size = 12, hjust = 1),
axis.text.y =
element_text(size=12))+
coord_fixed()+
geom_text(aes(Var1,Var2, label = value), color = "black", size =4)+
theme(
axis.title.x = element_blank(),
axis.title.y = element_blank(),
)
# pairplot
ggpairs(df_billet_dropna.full,             # Dataframe
columns = 2:7,         # Columns
aes(color=is_genuine, # Color by group
alpha = 0.5)
)
l
l
# Removing the is_genuine variable for multiple linear regression
df_billet_dropna <- df_billet_dropna.full[-1]
# Partition of data into a train dataframe and a test dataframe
# set.seed
set.seed(123)
# Partition at 80% in the train data and 20% for the test data.
row.number <- sample(1:nrow(df_billet_dropna), 0.8*nrow(df_billet_dropna))
train <- df_billet_dropna[row.number,]
test <- df_billet_dropna[-row.number,]
# Fit the complete model with "margin_low" on the "train" data
full.model <- lm(margin_low ~., data = train)
# Stepwise regression model with the full model
step.model <- stepAIC(full.model, direction = "both",
trace = FALSE)
summary(step.model)
broom::glance(step.model)
# Check VIF :
check_collinearity(step.model)
# Check model
check_model(step.model)
# residual analysis
billet.residuals <- data.frame(residuals = step.model$residuals)
# Histogram overlaid with Kernel density Curve
billet.residuals %>% ggplot(aes(x=residuals))+
geom_histogram(aes(y=..density..),
binwidth=.05,
colour = 'black',fill="steelblue")+
geom_density(alpha = .2, fill = "red")
x = model.matrix(margin_low~.,df_billet_dropna)  # values without margin_low
y = as.matrix(df_billet_dropna$margin_low) # values with margin_low
colnames(y) = "margin_low"
train_a = as.integer(rownames(train)) # dataframe train index
test_a = as.integer(rownames(test)) # dataframe test index
mod.coef = step.model$coefficients # coefficients
mod.pred = predict(step.model,newdata=data.frame(x)) # predictions on the test set
reg_mse <- mean((mod.pred[test_a]-y[test_a])^2) # Test MSE
reg_mse
mod.coef
# Imputation of missing data
df_billet_nan <- df_billet %>% filter(if_any(everything(), is.na)) # dataframe with missing data
predict_value <- predict(step.model,newdata = df_billet_nan) # prediction with the model on missing data
df_billet$margin_low[which(is.na(df_billet$margin_low))] <- predict_value  # replacement of missing values, by the model prediction
summary(df_billet)
# ACP
res.pca <- PCA(df_billet[,2:7],
scale.unit = TRUE,
graph = FALSE)
# Eigenvalue
eig.val <- get_eigenvalue(res.pca)
eig.val
# Scree Plot
fviz_eig(res.pca, addlabels = TRUE, ylim = c(0,50))
# Graph of variables
var <- get_pca_var(res.pca)
# Coordinates
var$coord[,1:2]
# Cos2: quality
var$cos2[,1:2]
#Graph
corrplot(var$cos2,
is.corr=FALSE, method = "color", addCoef.col = "black",
col = colorRampPalette(c("white", "deepskyblue", "blue"))(100),
tl.col = "black", tl.srt = 45)
# Contributions to the principal components
var$contrib[,1:2]
corrplot(var$contrib,
is.corr=FALSE, method = "color", addCoef.col = "black",
col = colorRampPalette(c("white", "deepskyblue", "blue"))(100),
tl.col = "black", tl.srt = 45)
# Visualization on correlation circle
fviz_pca_var(res.pca, col.var = "black")
# Description des dimensions
res.desc <- dimdesc(res.pca, axes = c(1,2), proba = 0.05)
# Description de la dimension 1
res.desc$Dim.1
# Coordinates of individuals
head(ind$coord)
# Quality of the individuals
head(ind$cos2)
# Graph of individuals
ind <- get_pca_ind(res.pca)
# Coordinates of individuals
head(ind$coord)
# Quality of the individuals
head(ind$cos2)
# Contributions of the individuals
head(ind$contrib)
# Graph of the individuals
fviz_pca_ind(res.pca,
axes = c(1,2),
geom.ind = "point", # show points only
col.ind = df_billet$is_genuine, # color by is_genuine
addEllipses = TRUE, # concentration ellipses
legend.title = "Nature of the bills"
)
# Visualization of the dataframe
str(df_billet) # info about data
# Clustering with K-means
# Mission K-means
set.seed(123)
kmeans.result <- kmeans(x = df_billet[,2:7], 2) # Cutting in 2 groups because we have 2 kinds of bills
# Centroids of K-means
kmeans.result$centers
# Cluster list
kmeans.clusters <- kmeans.result$cluster
# Confusion Matrix
cmat <- confusionMatrix(
table(
"reference" = factor(df_billet$is_genuine,
levels = c("vrai_billet","faux_billet")),
"prediction" = factor(kmeans.clusters,
levels = c(1,2),
labels = c("vrai_billet","faux_billet"))
)
)
cmat
# Graph
fourfoldplot(cmat$table, color = c("#FFCAC9","#91FFB4"),
conf.level = 0, margin = 1
)
# Visualization on the 1st factorial plane
kmeans.acp.label <- factor(paste(kmeans.clusters, df_billet$is_genuine, sep = ' - '),
levels = c("1 - vrai_billet","2 - vrai_billet", "2 - faux_billet", "1 - faux_billet"),
labels = c("vrai positif", "faux positif", "vrai négatif","faux négatif"))
fviz_pca_ind(res.pca,
axes = c(1,2),
geom.ind = "point", # montre les points seulement
col.ind = kmeans.acp.label,
legend.title = "Nature du billet",
mean_point = FALSE
)
# set.seed
set.seed (123)
# We partition our data with 80% in the train data and 20% in the test data
training.samples <- df_billet$is_genuine %>% createDataPartition(p = 0.8, list = FALSE)
train.data <- df_billet[training.samples, ]
test.data <- df_billet[-training.samples, ]
# Train :
table(train.data$is_genuine)
# Test
table(test.data$is_genuine)
### Model calculation with the *stepwise* approach
log.full_model <- glm(is_genuine ~., data = train.data, family = "binomial"(link="logit"))
log.step_model <- stepAIC(log.full_model,
data = train.data,
direction ="both", trace = FALSE)
test_model <- glm(is_genuine ~.-diagonal-height_left, data = train.data, family = "binomial")
summary(log.full_model)
summary(log.step_model)
summary(test_model)
# The selected variables and their coefficients
log.step_model$coefficients
# Prediction
probabilities <- log.step_model %>% predict(test.data, type = "response")
predicted.classes <- ifelse(probabilities < 0.5, "vrai_billet", "faux_billet")
# Model precision
mean(predicted.classes == test.data$is_genuine)
# Confusion Matrix
log.cmat <- confusionMatrix(
table(
"prediction" = factor(predicted.classes,
levels = c("vrai_billet", "faux_billet")),
"is_genuine" = factor(test.data$is_genuine,
levels = c("vrai_billet", "faux_billet"))
)
)
log.cmat
fourfoldplot(log.cmat$table, color = c("#FFCAC9","#91FFB4"),
conf.level = 0, margin = 1
)
# Projection sur le 1er plan factoriel
acp_label = as.character(df_billet$is_genuine)
acp_label[as.integer(rownames(test.data))] = "inconnu" # transformation ID in integer
acp_label = factor(acp_label)
vp_fn = factor(paste(test.data$is_genuine,predicted.classes))
levels(vp_fn) = c('Vrai négatif','Faux Positif', 'Faux Négatif', 'Vrai Positif')
names(vp_fn) = as.integer(rownames(test.data))
# Calcul of the labels for the 2nd PCA
acp_label2 = as.character(df_billet$is_genuine)
names(acp_label2) = as.integer(rownames(df_billet))
acp_label2[names(vp_fn)] = as.character(vp_fn)
acp_label2 = as.factor(acp_label2)
fig1 = fviz_pca_ind(res.pca,
geom=c('point'),
pointshape = 19,
habillage = acp_label,
palette = c('#FFCAC9',  'black', '#91FFB4'),
mean.point = FALSE,
legend.title = "Nature du billet"
)
fig1
fig2 = fviz_pca_ind(res.pca,
geom=c('point'),
pointshape = 19,
habillage = acp_label2,
palette = c('#000FB2', # faux négatif
'#7B01B2', # faux positif
'#FFCAC9', # faux billet
'#B20000', # vrai negatif
'#00B233', # vrai positif
'#91FFB4' # vrai billet
),
mean.point = FALSE,
legend.title = "Nature du billet"
)
fig2
roc(test.data$is_genuine ~ probabilities, plot = TRUE, print.auc = TRUE, col ="#00B233", lwd = 4, legacy.axes = TRUE, main = "ROC Curves")
# Importing the additional dataset
df_billet_production <- read.csv2("data/billets_test.csv", sep = ",", dec = ".")
# Importing the additional dataset
df_billet_production <- read.csv2("data/billets_test.csv", sep = ",", dec = ".")
# Test set
probabilities_production <- log.step_model %>% predict(df_billet_production, type = "response")
predicted.classes_production <- ifelse(probabilities_production < 0.5, "vrai_billet", "faux_billet")
df_billet_production["nature_billet"] <- predicted.classes_production
df_billet_production["proba"] <- round(probabilities_production, 5)*100
# Dataframe visualization
kable(df_billet_production)%>%
kable_styling(latex_options = 'striped')
# Importing the additional dataset
df_billet_production <- read.csv2("data/billets_test.csv", sep = ",", dec = ".")
# Test set
df_billet_production$prediction <- cl_predict(kmeans.result,
df_billet_production %>%
dplyr::select(-id))
# Dataframe visualization
kable(df_billet_production)%>%
kable_styling(latex_options = 'striped')
source("~/.active-rstudio-document", echo=TRUE)
source("~/.active-rstudio-document", echo=TRUE)
